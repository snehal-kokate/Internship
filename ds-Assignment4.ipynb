{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed060cbb",
   "metadata": {},
   "source": [
    "# Q1.Scrape the details of most viewed videos on YouTube from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b79ecef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 1.\n",
      "Name: \"Baby Shark Dance\"[6]\n",
      "Artist: Pinkfong Baby Shark - Kids' Songs & Stories\n",
      "Upload Date: June 17, 2016\n",
      "Views: 12.85\n",
      "\n",
      "Rank: 2.\n",
      "Name: \"Despacito\"[9]\n",
      "Artist: Luis Fonsi\n",
      "Upload Date: January 12, 2017\n",
      "Views: 8.16\n",
      "\n",
      "Rank: 3.\n",
      "Name: \"Johny Johny Yes Papa\"[16]\n",
      "Artist: LooLoo Kids\n",
      "Upload Date: October 8, 2016\n",
      "Views: 6.70\n",
      "\n",
      "Rank: 4.\n",
      "Name: \"Bath Song\"[17]\n",
      "Artist: Cocomelon – Nursery Rhymes\n",
      "Upload Date: May 2, 2018\n",
      "Views: 6.20\n",
      "\n",
      "Rank: 5.\n",
      "Name: \"Shape of You\"[18]\n",
      "Artist: Ed Sheeran\n",
      "Upload Date: January 30, 2017\n",
      "Views: 6.00\n",
      "\n",
      "Rank: 6.\n",
      "Name: \"See You Again\"[21]\n",
      "Artist: Wiz Khalifa\n",
      "Upload Date: April 6, 2015\n",
      "Views: 5.89\n",
      "\n",
      "Rank: 7.\n",
      "Name: \"Phonics Song with Two Words\"[26]\n",
      "Artist: ChuChu TV\n",
      "Upload Date: March 6, 2014\n",
      "Views: 5.30\n",
      "\n",
      "Rank: 8.\n",
      "Name: \"Wheels on the Bus\"[27]\n",
      "Artist: Cocomelon – Nursery Rhymes\n",
      "Upload Date: May 24, 2018\n",
      "Views: 5.24\n",
      "\n",
      "Rank: 9.\n",
      "Name: \"Uptown Funk\"[28]\n",
      "Artist: Mark Ronson\n",
      "Upload Date: November 19, 2014\n",
      "Views: 4.92\n",
      "\n",
      "Rank: 10.\n",
      "Name: \"Learning Colors – Colorful Eggs on a Farm\"[29]\n",
      "Artist: Miroshka TV\n",
      "Upload Date: February 27, 2018\n",
      "Views: 4.89\n",
      "\n",
      "Rank: 11.\n",
      "Name: \"Gangnam Style\"[30]\n",
      "Artist: Psy\n",
      "Upload Date: July 15, 2012\n",
      "Views: 4.80\n",
      "\n",
      "Rank: 12.\n",
      "Name: \"Masha and the Bear – Recipe for Disaster\"[35]\n",
      "Artist: Get Movies\n",
      "Upload Date: January 31, 2012\n",
      "Views: 4.55\n",
      "\n",
      "Rank: 13.\n",
      "Name: \"Dame Tu Cosita\"[36]\n",
      "Artist: El Chombo\n",
      "Upload Date: April 5, 2018\n",
      "Views: 4.35\n",
      "\n",
      "Rank: 14.\n",
      "Name: \"Axel F\"[37]\n",
      "Artist: Crazy Frog\n",
      "Upload Date: June 16, 2009\n",
      "Views: 3.91\n",
      "\n",
      "Rank: 15.\n",
      "Name: \"Sugar\"[38]\n",
      "Artist: Maroon 5\n",
      "Upload Date: January 14, 2015\n",
      "Views: 3.87\n",
      "\n",
      "Rank: 16.\n",
      "Name: \"Roar\"[39]\n",
      "Artist: Katy Perry\n",
      "Upload Date: September 5, 2013\n",
      "Views: 3.80\n",
      "\n",
      "Rank: 17.\n",
      "Name: \"Counting Stars\"[40]\n",
      "Artist: OneRepublic\n",
      "Upload Date: May 31, 2013\n",
      "Views: 3.79\n",
      "\n",
      "Rank: 18.\n",
      "Name: \"Sorry\"[41]\n",
      "Artist: Justin Bieber\n",
      "Upload Date: October 22, 2015\n",
      "Views: 3.66\n",
      "\n",
      "Rank: 19.\n",
      "Name: \"Baa Baa Black Sheep\"[42]\n",
      "Artist: Cocomelon – Nursery Rhymes\n",
      "Upload Date: June 25, 2018\n",
      "Views: 3.64\n",
      "\n",
      "Rank: 20.\n",
      "Name: \"Thinking Out Loud\"[43]\n",
      "Artist: Ed Sheeran\n",
      "Upload Date: October 7, 2014\n",
      "Views: 3.60\n",
      "\n",
      "Rank: 21.\n",
      "Name: \"Waka Waka (This Time for Africa)\"[44]\n",
      "Artist: Shakira\n",
      "Upload Date: June 4, 2010\n",
      "Views: 3.59\n",
      "\n",
      "Rank: 22.\n",
      "Name: \"Dark Horse\"[45]\n",
      "Artist: Katy Perry\n",
      "Upload Date: February 20, 2014\n",
      "Views: 3.52\n",
      "\n",
      "Rank: 23.\n",
      "Name: \"Lakdi Ki Kathi\"[46]\n",
      "Artist: Jingle Toons\n",
      "Upload Date: June 14, 2018\n",
      "Views: 3.48\n",
      "\n",
      "Rank: 24.\n",
      "Name: \"Faded\"[47]\n",
      "Artist: Alan Walker\n",
      "Upload Date: December 3, 2015\n",
      "Views: 3.45\n",
      "\n",
      "Rank: 25.\n",
      "Name: \"Perfect\"[48]\n",
      "Artist: Ed Sheeran\n",
      "Upload Date: November 9, 2017\n",
      "Views: 3.45\n",
      "\n",
      "Rank: 26.\n",
      "Name: \"Let Her Go\"[49]\n",
      "Artist: Passenger\n",
      "Upload Date: July 25, 2012\n",
      "Views: 3.44\n",
      "\n",
      "Rank: 27.\n",
      "Name: \"Girls Like You\"[50]\n",
      "Artist: Maroon 5\n",
      "Upload Date: May 31, 2018\n",
      "Views: 3.42\n",
      "\n",
      "Rank: 28.\n",
      "Name: \"Humpty the train on a fruits ride\"[51]\n",
      "Artist: Kiddiestv Hindi – Nursery Rhymes & Kids Songs\n",
      "Upload Date: January 26, 2018\n",
      "Views: 3.41\n",
      "\n",
      "Rank: 29.\n",
      "Name: \"Lean On\"[52]\n",
      "Artist: Major Lazer\n",
      "Upload Date: March 22, 2015\n",
      "Views: 3.38\n",
      "\n",
      "Rank: 30.\n",
      "Name: \"Bailando\"[53]\n",
      "Artist: Enrique Iglesias\n",
      "Upload Date: April 11, 2014\n",
      "Views: 3.38\n",
      "\n",
      "Error: Insufficient columns in a row\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request to the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the most viewed videos\n",
    "table = soup.find(\"table\", {\"class\": \"wikitable sortable\"})\n",
    "\n",
    "# Iterate over each row in the table (excluding the header row)\n",
    "rows = table.find_all(\"tr\")[1:]\n",
    "for row in rows:\n",
    "    try:\n",
    "        # Get the columns for each row\n",
    "        columns = row.find_all(\"td\")\n",
    "\n",
    "        # Extract the required details\n",
    "        rank = columns[0].text.strip()\n",
    "        name = columns[1].text.strip()\n",
    "        artist = columns[2].text.strip()\n",
    "        upload_date = columns[4].text.strip()\n",
    "        views = columns[3].text.strip()\n",
    "\n",
    "        # Print the details\n",
    "        print(\"Rank:\", rank)\n",
    "        print(\"Name:\", name)\n",
    "        print(\"Artist:\", artist)\n",
    "        print(\"Upload Date:\", upload_date)\n",
    "        print(\"Views:\", views)\n",
    "        print()\n",
    "\n",
    "    except IndexError:\n",
    "        # Handle the case when the number of columns is insufficient\n",
    "        print(\"Error: Insufficient columns in a row\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbadf654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ccb198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f83b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Scrape the details teamIndia’sinternationalfixtures from bcci.tv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "537411e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_Title = []\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dea6c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SNEHAL\\AppData\\Local\\Temp\\ipykernel_25528\\4276506912.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "\n",
    "# Open the BCCI website\n",
    "driver.get('https://www.bcci.tv/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac6bc6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = driver.find_element(By.XPATH,'//li[@class=\"nav-item\"]//a')\n",
    "page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db316304",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_elements = driver.find_elements(By.XPATH, '//div[@class=\"match-card-top\"]//h5')\n",
    "#no need to append ...using list comphrension\n",
    "Match_Title = [element.text for element in title_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbe091ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_elements = driver.find_elements(By.XPATH, '//span[@class=\"ng-binding ng-scope\"]')\n",
    "Place = [element.text for element in place_elements]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e509fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_elements = driver.find_elements(By.XPATH, '//div[@class=\"match-card-middle d-flex\"]')\n",
    "Series = [element.text for element in series_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51d5ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_elements = driver.find_elements(By.XPATH, '//div[@class=\"match-dates ng-binding\"]')\n",
    "Date = [element.text for element in date_elements]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac66b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_elements = driver.find_elements(By.XPATH, '//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "Time = [element.text for element in time_elements]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd5a5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame([])\n",
    "df['Title']=Match_Title\n",
    "df['Series']=Series\n",
    "df['Place']=Place\n",
    "df['Date']=Date\n",
    "df['Time']=Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "580ded60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Bangladesh Women\\nvs\\nIndia Women</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>9 JUL 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Bangladesh Women\\nvs\\nIndia Women</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>11 JUL 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>West Indies\\nvs\\nIndia</td>\n",
       "      <td>Windsor Park,</td>\n",
       "      <td>12 JUL 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Bangladesh Women\\nvs\\nIndia Women</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>13 JUL 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Bangladesh Women\\nvs\\nIndia Women</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>16 JUL 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Bangladesh Women\\nvs\\nIndia Women</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>19 JUL 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>West Indies\\nvs\\nIndia</td>\n",
       "      <td>Queen's Park Oval,</td>\n",
       "      <td>20 JUL 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH 2023</td>\n",
       "      <td>Bangladesh Women\\nvs\\nIndia Women</td>\n",
       "      <td>Shere Bangla National Stadium, Mirpur,</td>\n",
       "      <td>22 JUL 2023</td>\n",
       "      <td>9:00 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title                             Series  \\\n",
       "0  INDIA WOMEN TOUR OF BANGLADESH 2023  Bangladesh Women\\nvs\\nIndia Women   \n",
       "1  INDIA WOMEN TOUR OF BANGLADESH 2023  Bangladesh Women\\nvs\\nIndia Women   \n",
       "2       INDIA TOUR OF WEST INDIES 2023             West Indies\\nvs\\nIndia   \n",
       "3  INDIA WOMEN TOUR OF BANGLADESH 2023  Bangladesh Women\\nvs\\nIndia Women   \n",
       "4  INDIA WOMEN TOUR OF BANGLADESH 2023  Bangladesh Women\\nvs\\nIndia Women   \n",
       "5  INDIA WOMEN TOUR OF BANGLADESH 2023  Bangladesh Women\\nvs\\nIndia Women   \n",
       "6       INDIA TOUR OF WEST INDIES 2023             West Indies\\nvs\\nIndia   \n",
       "7  INDIA WOMEN TOUR OF BANGLADESH 2023  Bangladesh Women\\nvs\\nIndia Women   \n",
       "\n",
       "                                    Place         Date         Time  \n",
       "0  Shere Bangla National Stadium, Mirpur,   9 JUL 2023  1:30 PM IST  \n",
       "1  Shere Bangla National Stadium, Mirpur,  11 JUL 2023  1:30 PM IST  \n",
       "2                           Windsor Park,  12 JUL 2023  7:30 PM IST  \n",
       "3  Shere Bangla National Stadium, Mirpur,  13 JUL 2023  1:30 PM IST  \n",
       "4  Shere Bangla National Stadium, Mirpur,  16 JUL 2023  9:00 AM IST  \n",
       "5  Shere Bangla National Stadium, Mirpur,  19 JUL 2023  9:00 AM IST  \n",
       "6                      Queen's Park Oval,  20 JUL 2023  7:30 PM IST  \n",
       "7  Shere Bangla National Stadium, Mirpur,  22 JUL 2023  9:00 AM IST  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b359c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.Scrape the details of State-wise GDP ofIndia fromstatisticstime.com. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba38230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SNEHAL\\AppData\\Local\\Temp\\ipykernel_25528\\2000016552.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver3 = webdriver.Chrome(r\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver3 = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver3.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18a6aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank = []\n",
    "State = []\n",
    "Share = []\n",
    "GDP = []\n",
    "GSDP_cur19_20 = []\n",
    "GSDP_cur18_19 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99672550",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy = driver3.find_element(By.XPATH,'//*[@id=\"top\"]/div[2]/div[2]/button')       # Locating page foe top videos by xpath\n",
    "economy.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba2c3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = driver3.find_element(By.XPATH,'//*[@id=\"top\"]/div[2]/div[2]/div/a[3]')       # Locating page foe top videos by xpath\n",
    "ind.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa1b2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = driver3.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')       # Locating page foe top videos by xpath\n",
    "gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2e79379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '']\n"
     ]
    }
   ],
   "source": [
    "rank = driver3.find_elements(By.XPATH,'//td[@class=\"data1\"]')\n",
    "for i in rank:\n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "print(len(Rank),Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b49eed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = driver3.find_elements(By.XPATH,'//td[@class=\"name\"]')\n",
    "for i in state:\n",
    "    if i.text is None:\n",
    "        State.append('--')\n",
    "    else:\n",
    "        State.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fa8206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "share = driver3.find_elements(By.XPATH,'//td[@class=\"data\"]')\n",
    "for i in share:\n",
    "    if i.text is None:\n",
    "        Share.append('--')\n",
    "    else:\n",
    "        Share.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccf2efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = driver3.find_elements(By.XPATH,'//tr[@class=\"odd\"]//td[6]')\n",
    "for i in gdp:\n",
    "    if i.text is None:\n",
    "        GDP.append('--')\n",
    "    else:\n",
    "        GDP.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5df6485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsdp1 = driver3.find_elements(By.XPATH,'//tr[@class=\"odd\"]//td[3]')\n",
    "for i in gsdp1:\n",
    "    if i.text is None:\n",
    "        GSDP_cur19_20.append('--')\n",
    "    else:\n",
    "        GSDP_cur19_20.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4885297",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsdp2 = driver3.find_elements(By.XPATH,'//tr[@class=\"odd\"]//td[4]')\n",
    "for i in gsdp2:\n",
    "    if i.text is None:\n",
    "        GSDP_cur18_19.append('--')\n",
    "    else:\n",
    "        GSDP_cur18_19.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf6a5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame([])\n",
    "df2['Rank'] = Rank[:30]\n",
    "df2['State'] = State[:30]\n",
    "df2['Share'] = Share[:30]\n",
    "df2['GDP'] = GDP[:30]\n",
    "df2['GSDP_cur(19-20)'] = GSDP_cur19_20[:30]\n",
    "df2['GSDP_cur(18-19)'] = GSDP_cur18_19[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf3ee2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP</th>\n",
       "      <th>GSDP_cur(19-20)</th>\n",
       "      <th>GSDP_cur(18-19)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>399.921</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>240.726</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>399.921</td>\n",
       "      <td>226.806</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>143.179</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,039,074</td>\n",
       "      <td>130.791</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>118.733</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>111.519</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>247.629</td>\n",
       "      <td>79.957</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,312,929</td>\n",
       "      <td>47.982</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,215,307</td>\n",
       "      <td>45.145</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>23.690</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>11.115</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>240.726</td>\n",
       "      <td>6.397</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>1,166,817</td>\n",
       "      <td>5.086</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>1,123,982</td>\n",
       "      <td>4.233</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>-</td>\n",
       "      <td>3.737</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>228.290</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2,332,992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>-</td>\n",
       "      <td>1,015,735</td>\n",
       "      <td>1,495,758</td>\n",
       "      <td>1,404,761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>1,186,379</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1,322,936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>630,693</td>\n",
       "      <td>916,014</td>\n",
       "      <td>845,247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>595,605</td>\n",
       "      <td>875,429</td>\n",
       "      <td>776,140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>226.806</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>707,542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>1,156,039</td>\n",
       "      <td>514,983</td>\n",
       "      <td>755,790</td>\n",
       "      <td>666,075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>1,091,077</td>\n",
       "      <td>374,015</td>\n",
       "      <td>517,521</td>\n",
       "      <td>472,506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>282,782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>210,837</td>\n",
       "      <td>288,041</td>\n",
       "      <td>266,537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>165.556</td>\n",
       "      <td>107,171</td>\n",
       "      <td>143,063</td>\n",
       "      <td>133,303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>793,223</td>\n",
       "      <td>56,810</td>\n",
       "      <td>72,181</td>\n",
       "      <td>66,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>739,525</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>37,571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank             State      Share        GDP GSDP_cur(19-20)  \\\n",
       "0     1       Maharashtra          -    399.921               -   \n",
       "1     2        Tamil Nadu     13.94%    240.726       1,687,818   \n",
       "2     3     Uttar Pradesh    399.921    226.806       1,631,977   \n",
       "3     4           Gujarat          -    143.179       1,020,989   \n",
       "4     5         Karnataka  2,039,074    130.791         969,604   \n",
       "5     6       West Bengal  1,845,853    118.733               -   \n",
       "6     7         Rajasthan      8.63%    111.519         831,610   \n",
       "7     8    Andhra Pradesh    247.629     79.957         574,760   \n",
       "8     9         Telangana  1,312,929     47.982               -   \n",
       "9    10    Madhya Pradesh  1,215,307     45.145         328,598   \n",
       "10   11            Kerala  1,687,818     23.690               -   \n",
       "11   12             Delhi      8.39%     11.115          80,449   \n",
       "12   13           Haryana    240.726      6.397               -   \n",
       "13   14             Bihar  1,166,817      5.086          36,572   \n",
       "14   15            Punjab  1,123,982      4.233          31,790   \n",
       "15   16            Odisha          -      3.737               -   \n",
       "16   17             Assam      7.96%          -               -   \n",
       "17   18      Chhattisgarh    228.290          -               -   \n",
       "18   19         Jharkhand          -  1,015,735       1,495,758   \n",
       "19   20       Uttarakhand  1,186,379          -               -   \n",
       "20   21   Jammu & Kashmir  1,631,977    630,693         916,014   \n",
       "21   22  Himachal Pradesh      7.91%    595,605         875,429   \n",
       "22   23               Goa    226.806          -               -   \n",
       "23   24           Tripura  1,156,039    514,983         755,790   \n",
       "24   25        Chandigarh  1,091,077    374,015         517,521   \n",
       "25   26        Puducherry  1,253,832          -               -   \n",
       "26   27         Meghalaya      5.77%    210,837         288,041   \n",
       "27   28            Sikkim    165.556    107,171         143,063   \n",
       "28   29           Manipur    793,223     56,810          72,181   \n",
       "29   30          Nagaland    739,525          -               -   \n",
       "\n",
       "   GSDP_cur(18-19)  \n",
       "0        2,632,792  \n",
       "1        1,584,764  \n",
       "2        1,493,127  \n",
       "3          942,586  \n",
       "4          861,031  \n",
       "5          781,653  \n",
       "6          734,163  \n",
       "7          526,376  \n",
       "8          315,881  \n",
       "9          297,204  \n",
       "10         155,956  \n",
       "11          73,170  \n",
       "12          42,114  \n",
       "13          33,481  \n",
       "14          27,870  \n",
       "15          24,603  \n",
       "16               -  \n",
       "17       2,332,992  \n",
       "18       1,404,761  \n",
       "19       1,322,936  \n",
       "20         845,247  \n",
       "21         776,140  \n",
       "22         707,542  \n",
       "23         666,075  \n",
       "24         472,506  \n",
       "25         282,782  \n",
       "26         266,537  \n",
       "27         133,303  \n",
       "28          66,060  \n",
       "29          37,571  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9b94d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1242b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4.Scrape the details of trending repositories on Github.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36efb86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SNEHAL\\AppData\\Local\\Temp\\ipykernel_25528\\584403100.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver4 = webdriver.Chrome(r\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver4 = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver4.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32654d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = driver4.find_element(By.XPATH,'//li[3][@class=\"HeaderMenu-item position-relative flex-wrap flex-justify-between flex-items-center d-block d-lg-flex flex-lg-nowrap flex-lg-items-center js-details-container js-header-menu-item\"]') \n",
    "page.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd6dbeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = driver4.find_element(By.LINK_TEXT, \"Trending\")\n",
    "trend.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27fdb3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Description = []\n",
    "Language = []\n",
    "Count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c98da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = driver4.find_elements(By.XPATH,'//span[@class=\"text-normal\"]')\n",
    "for i in repo:\n",
    "    if i.text is None:\n",
    "        Title.append('nan')\n",
    "    else:\n",
    "        Title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccaabe3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ChaoningZhang /', 'ramonvc /', 'THUDM /', 'PowerShell /', 'XingangPan /', 'hiyouga /', 'facebook /', 'THUDM /', 'practical-tutorials /', 'sohamkamani /', 'papers-we-love /', 'cvg /', 'turboderp /', 'fuqiuluo /', 'jasontaylordev /', 'toeverything /', 'ripienaar /', 'EbookFoundation /', 'chat2db /', 'PlexPt /', 'labmlai /', 'microsoft /', 'dragonflydb /', 'wgwang /', 'StanGirard /']\n"
     ]
    }
   ],
   "source": [
    "print(Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f831a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "des = driver4.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "for i in des:\n",
    "    if i.text is None:\n",
    "        Description.append('nan')\n",
    "    else:\n",
    "        Description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d4ba50b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = driver4.find_elements(By.XPATH,'//span[@itemprop=\"programmingLanguage\"]')\n",
    "for i in lang:\n",
    "    if i.text is None:\n",
    "        Language.append('nan')\n",
    "    else:\n",
    "        Language.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4d69ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = driver4.find_elements(By.XPATH,'//a[@class=\"Link--muted d-inline-block mr-3\"]')\n",
    "for i in count:\n",
    "    if i.text is None:\n",
    "        Count.append('nan')\n",
    "    else:\n",
    "        Count.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbb3b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame([])\n",
    "df4['Title'] = Title[:20]\n",
    "df4['Description'] = Description[:20]\n",
    "df4['Language'] = Language[:20]\n",
    "df4['Count'] = Count[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d68624b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Language</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChaoningZhang /</td>\n",
       "      <td>This is the offiicial code for Faster Segment ...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>1,492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ramonvc /</td>\n",
       "      <td>GPT 3.5/4 with a Chat Web UI. No API key requi...</td>\n",
       "      <td>Python</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THUDM /</td>\n",
       "      <td>ChatGLM2-6B: An Open Bilingual Chat LLM | 开源双语...</td>\n",
       "      <td>Python</td>\n",
       "      <td>1,557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PowerShell /</td>\n",
       "      <td>PowerShell for every system!</td>\n",
       "      <td>C#</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XingangPan /</td>\n",
       "      <td>Official Code for DragGAN (SIGGRAPH 2023)</td>\n",
       "      <td>Python</td>\n",
       "      <td>6,228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hiyouga /</td>\n",
       "      <td>Fine-tuning ChatGLM-6B with PEFT | 基于 PEFT 的高效...</td>\n",
       "      <td>Python</td>\n",
       "      <td>1,076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>facebook /</td>\n",
       "      <td>An open-source C++ library developed and used ...</td>\n",
       "      <td>C++</td>\n",
       "      <td>39,013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>THUDM /</td>\n",
       "      <td>ChatGLM-6B: An Open Bilingual Dialogue Languag...</td>\n",
       "      <td>Python</td>\n",
       "      <td>6,843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>practical-tutorials /</td>\n",
       "      <td>Curated list of project-based tutorials</td>\n",
       "      <td>Shell</td>\n",
       "      <td>27,666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sohamkamani /</td>\n",
       "      <td>An ultra-simplified explanation of design patt...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>2,852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>papers-we-love /</td>\n",
       "      <td>Papers from the computer science community to ...</td>\n",
       "      <td>Python</td>\n",
       "      <td>1,669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cvg /</td>\n",
       "      <td>LightGlue: Local Feature Matching at Light Speed</td>\n",
       "      <td>Kotlin</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>turboderp /</td>\n",
       "      <td>A more memory-efficient rewrite of the HF tran...</td>\n",
       "      <td>C#</td>\n",
       "      <td>25,455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fuqiuluo /</td>\n",
       "      <td>获取QQSign通过Unidbg</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>5,235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jasontaylordev /</td>\n",
       "      <td>Clean Architecture Solution Template for ASP.N...</td>\n",
       "      <td>HTML</td>\n",
       "      <td>30,517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>toeverything /</td>\n",
       "      <td>There can be more than Notion and Miro. AFFiNE...</td>\n",
       "      <td>Java</td>\n",
       "      <td>4,028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ripienaar /</td>\n",
       "      <td>A list of SaaS, PaaS and IaaS offerings that h...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>108,189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EbookFoundation /</td>\n",
       "      <td>📚 Freely available programming books</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>15,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chat2db /</td>\n",
       "      <td>🔥 🔥 🔥 An intelligent and versatile general-pur...</td>\n",
       "      <td>C++</td>\n",
       "      <td>3,967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PlexPt /</td>\n",
       "      <td>ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Title                                        Description  \\\n",
       "0         ChaoningZhang /  This is the offiicial code for Faster Segment ...   \n",
       "1               ramonvc /  GPT 3.5/4 with a Chat Web UI. No API key requi...   \n",
       "2                 THUDM /  ChatGLM2-6B: An Open Bilingual Chat LLM | 开源双语...   \n",
       "3            PowerShell /                       PowerShell for every system!   \n",
       "4            XingangPan /          Official Code for DragGAN (SIGGRAPH 2023)   \n",
       "5               hiyouga /  Fine-tuning ChatGLM-6B with PEFT | 基于 PEFT 的高效...   \n",
       "6              facebook /  An open-source C++ library developed and used ...   \n",
       "7                 THUDM /  ChatGLM-6B: An Open Bilingual Dialogue Languag...   \n",
       "8   practical-tutorials /            Curated list of project-based tutorials   \n",
       "9           sohamkamani /  An ultra-simplified explanation of design patt...   \n",
       "10       papers-we-love /  Papers from the computer science community to ...   \n",
       "11                  cvg /   LightGlue: Local Feature Matching at Light Speed   \n",
       "12            turboderp /  A more memory-efficient rewrite of the HF tran...   \n",
       "13             fuqiuluo /                                   获取QQSign通过Unidbg   \n",
       "14       jasontaylordev /  Clean Architecture Solution Template for ASP.N...   \n",
       "15         toeverything /  There can be more than Notion and Miro. AFFiNE...   \n",
       "16            ripienaar /  A list of SaaS, PaaS and IaaS offerings that h...   \n",
       "17      EbookFoundation /               📚 Freely available programming books   \n",
       "18              chat2db /  🔥 🔥 🔥 An intelligent and versatile general-pur...   \n",
       "19               PlexPt /                ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。   \n",
       "\n",
       "            Language    Count  \n",
       "0   Jupyter Notebook    1,492  \n",
       "1             Python      301  \n",
       "2             Python    1,557  \n",
       "3                 C#      555  \n",
       "4             Python    6,228  \n",
       "5             Python    1,076  \n",
       "6                C++   39,013  \n",
       "7             Python    6,843  \n",
       "8              Shell   27,666  \n",
       "9   Jupyter Notebook    2,852  \n",
       "10            Python    1,669  \n",
       "11            Kotlin      218  \n",
       "12                C#   25,455  \n",
       "13        TypeScript    5,235  \n",
       "14              HTML   30,517  \n",
       "15              Java    4,028  \n",
       "16  Jupyter Notebook  108,189  \n",
       "17        JavaScript   15,100  \n",
       "18               C++    3,967  \n",
       "19        TypeScript      468  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f58787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2154497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5.Scrape the details of top 100 songs on billiboard.com. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da0477c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SNEHAL\\AppData\\Local\\Temp\\ipykernel_25528\\2522005584.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver5 = webdriver.Chrome(r\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver5 = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver5.get(' https:/www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "568d20ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bill = driver5.find_element(By.XPATH, '/html/body/div[3]/main/div[2]/div[1]/div[1]/div[1]/div[2]/div/div[2]/a[1]')\n",
    "bill.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d788750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song_name = []\n",
    "Artist = []\n",
    "Last_rank = []\n",
    "Peak_rank = []\n",
    "Week_onboard = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b4ba19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "song =driver5.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//ul//li//h3')\n",
    "for i in song:\n",
    "    if i.text is None:\n",
    "        Song_name.append('--')\n",
    "    else:\n",
    "        Song_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "201ebba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "art = driver5.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//ul//li//span')\n",
    "for i in art:\n",
    "    if i.text is None:\n",
    "        Artist.append('--')\n",
    "    else:\n",
    "        Artist.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d72c3730",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = driver5.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//ul//li[4]//span')\n",
    "for i in last:\n",
    "    if i.text is None:\n",
    "        Last_rank.append('--')\n",
    "    else:\n",
    "        Last_rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f942ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak = driver5.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//ul//li[5]//span')\n",
    "for i in peak:\n",
    "    if i.text is None:\n",
    "        Peak_rank.append('--')\n",
    "    else:\n",
    "        Peak_rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "95f2f9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "week = driver5.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//ul//li[6]//span')\n",
    "for i in week:\n",
    "    if i.text is None:\n",
    "        Week_onboard.append('--')\n",
    "    else:\n",
    "        Week_onboard.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c7d8980",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame([])\n",
    "df5['Song Name'] = Song_name[:100]\n",
    "df5['Artist'] = Artist[:100]\n",
    "df5['Last Week Rank'] = Last_rank[:100]\n",
    "df5['Peak Rank'] = Peak_rank[:100]\n",
    "df5['Week Onboard'] = Week_onboard[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd488007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Week Onboard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One Thing At A Time</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The World EP.2 : Outlaw</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Gift &amp; A Curse</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Midnights</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOS</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Blonde</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>beerbongs &amp; bentleys</td>\n",
       "      <td></td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Greatest Hits So Far...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>=</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Gold: Greatest Hits</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Song Name         Artist Last Week Rank Peak Rank  \\\n",
       "0       One Thing At A Time  Morgan Wallen              1         1   \n",
       "1   The World EP.2 : Outlaw              1                            \n",
       "2          A Gift & A Curse              1              -         2   \n",
       "3                 Midnights             16                            \n",
       "4                       SOS                             -         3   \n",
       "..                      ...            ...            ...       ...   \n",
       "95                   Blonde                                           \n",
       "96     beerbongs & bentleys                            54         2   \n",
       "97  Greatest Hits So Far...                                           \n",
       "98                        =      Bad Bunny             52         3   \n",
       "99      Gold: Greatest Hits             14                            \n",
       "\n",
       "   Week Onboard  \n",
       "0            16  \n",
       "1             1  \n",
       "2             1  \n",
       "3            35  \n",
       "4            28  \n",
       "..          ...  \n",
       "95          335  \n",
       "96          269  \n",
       "97          368  \n",
       "98           86  \n",
       "99          279  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a7b01348",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6.Scrape the details of Highest sellingnovels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e99be297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SNEHAL\\AppData\\Local\\Temp\\ipykernel_25528\\298265003.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver6 = webdriver.Chrome(r\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver6 = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver6.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10dedc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Book_name = []\n",
    "Author = []\n",
    "Sold = []\n",
    "Publisher = []\n",
    "Genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "86311ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = driver6.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e9c6276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row and extract the column of table\n",
    "for row in rows:\n",
    "    # Get the values from each column in the row\n",
    "    columns = row.find_elements(By.TAG_NAME,'td')\n",
    "    title = columns[1].text\n",
    "    Book_name.append(title)\n",
    "    author = columns[2].text\n",
    "    Author.append(author)\n",
    "    sold = columns[3].text\n",
    "    Sold.append(sold)\n",
    "    pub = columns[4].text\n",
    "    Publisher.append(pub)\n",
    "    gen = columns[5].text\n",
    "    Genre.append(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9eb044da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.DataFrame([])\n",
    "df6['Book Name'] = Book_name[:30]\n",
    "df6['Author'] = Author[:30]\n",
    "df6['Volume Sales'] = Sold[:30]\n",
    "df6['Publisher'] = Publisher[:30]\n",
    "df6['Genre'] = Genre[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "44ebaf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume Sales</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harry Potter and the Goblet of Fire</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,583,215</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harry Potter and the Chamber of Secrets</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,484,047</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,377,906</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Angels and Demons</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>3,193,946</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Harry Potter and the Half-blood Prince:Childre...</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>2,950,264</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fifty Shades Darker</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>2,479,784</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,315,405</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Girl with the Dragon Tattoo,The:Millennium Tri...</td>\n",
       "      <td>Larsson, Stieg</td>\n",
       "      <td>2,233,570</td>\n",
       "      <td>Quercus</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fifty Shades Freed</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>2,193,928</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lost Symbol,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>2,183,031</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>New Moon</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,152,737</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Deception Point</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>2,062,145</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Eclipse</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,052,876</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lovely Bones,The</td>\n",
       "      <td>Sebold, Alice</td>\n",
       "      <td>2,005,598</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Curious Incident of the Dog in the Night-time,The</td>\n",
       "      <td>Haddon, Mark</td>\n",
       "      <td>1,979,552</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Digital Fortress</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>1,928,900</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Short History of Nearly Everything,A</td>\n",
       "      <td>Bryson, Bill</td>\n",
       "      <td>1,852,919</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Popular Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Girl Who Played with Fire,The:Millennium Trilogy</td>\n",
       "      <td>Larsson, Stieg</td>\n",
       "      <td>1,814,784</td>\n",
       "      <td>Quercus</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Breaking Dawn</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>1,787,118</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Very Hungry Caterpillar,The:The Very Hungry Ca...</td>\n",
       "      <td>Carle, Eric</td>\n",
       "      <td>1,783,535</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Picture Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gruffalo,The</td>\n",
       "      <td>Donaldson, Julia</td>\n",
       "      <td>1,781,269</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>Picture Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Jamie's 30-Minute Meals</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>1,743,266</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Kite Runner,The</td>\n",
       "      <td>Hosseini, Khaled</td>\n",
       "      <td>1,629,119</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>One Day</td>\n",
       "      <td>Nicholls, David</td>\n",
       "      <td>1,616,068</td>\n",
       "      <td>Hodder &amp; Stoughton</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Thousand Splendid Suns,A</td>\n",
       "      <td>Hosseini, Khaled</td>\n",
       "      <td>1,583,992</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "5                 Harry Potter and the Goblet of Fire     Rowling, J.K.   \n",
       "6             Harry Potter and the Chamber of Secrets     Rowling, J.K.   \n",
       "7            Harry Potter and the Prisoner of Azkaban     Rowling, J.K.   \n",
       "8                                   Angels and Demons        Brown, Dan   \n",
       "9   Harry Potter and the Half-blood Prince:Childre...     Rowling, J.K.   \n",
       "10                                Fifty Shades Darker      James, E. L.   \n",
       "11                                           Twilight  Meyer, Stephenie   \n",
       "12  Girl with the Dragon Tattoo,The:Millennium Tri...    Larsson, Stieg   \n",
       "13                                 Fifty Shades Freed      James, E. L.   \n",
       "14                                    Lost Symbol,The        Brown, Dan   \n",
       "15                                           New Moon  Meyer, Stephenie   \n",
       "16                                    Deception Point        Brown, Dan   \n",
       "17                                            Eclipse  Meyer, Stephenie   \n",
       "18                                   Lovely Bones,The     Sebold, Alice   \n",
       "19  Curious Incident of the Dog in the Night-time,The      Haddon, Mark   \n",
       "20                                   Digital Fortress        Brown, Dan   \n",
       "21               Short History of Nearly Everything,A      Bryson, Bill   \n",
       "22   Girl Who Played with Fire,The:Millennium Trilogy    Larsson, Stieg   \n",
       "23                                      Breaking Dawn  Meyer, Stephenie   \n",
       "24  Very Hungry Caterpillar,The:The Very Hungry Ca...       Carle, Eric   \n",
       "25                                       Gruffalo,The  Donaldson, Julia   \n",
       "26                            Jamie's 30-Minute Meals     Oliver, Jamie   \n",
       "27                                    Kite Runner,The  Hosseini, Khaled   \n",
       "28                                            One Day   Nicholls, David   \n",
       "29                           Thousand Splendid Suns,A  Hosseini, Khaled   \n",
       "\n",
       "   Volume Sales           Publisher                        Genre  \n",
       "0     5,094,805          Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152          Bloomsbury           Children's Fiction  \n",
       "2     4,200,654          Bloomsbury           Children's Fiction  \n",
       "3     4,179,479          Bloomsbury           Children's Fiction  \n",
       "4     3,758,936        Random House              Romance & Sagas  \n",
       "5     3,583,215          Bloomsbury           Children's Fiction  \n",
       "6     3,484,047          Bloomsbury           Children's Fiction  \n",
       "7     3,377,906          Bloomsbury           Children's Fiction  \n",
       "8     3,193,946          Transworld  Crime, Thriller & Adventure  \n",
       "9     2,950,264          Bloomsbury           Children's Fiction  \n",
       "10    2,479,784        Random House              Romance & Sagas  \n",
       "11    2,315,405  Little, Brown Book          Young Adult Fiction  \n",
       "12    2,233,570             Quercus  Crime, Thriller & Adventure  \n",
       "13    2,193,928        Random House              Romance & Sagas  \n",
       "14    2,183,031          Transworld  Crime, Thriller & Adventure  \n",
       "15    2,152,737  Little, Brown Book          Young Adult Fiction  \n",
       "16    2,062,145          Transworld  Crime, Thriller & Adventure  \n",
       "17    2,052,876  Little, Brown Book          Young Adult Fiction  \n",
       "18    2,005,598       Pan Macmillan   General & Literary Fiction  \n",
       "19    1,979,552        Random House   General & Literary Fiction  \n",
       "20    1,928,900          Transworld  Crime, Thriller & Adventure  \n",
       "21    1,852,919          Transworld              Popular Science  \n",
       "22    1,814,784             Quercus  Crime, Thriller & Adventure  \n",
       "23    1,787,118  Little, Brown Book          Young Adult Fiction  \n",
       "24    1,783,535             Penguin                Picture Books  \n",
       "25    1,781,269       Pan Macmillan                Picture Books  \n",
       "26    1,743,266             Penguin        Food & Drink: General  \n",
       "27    1,629,119          Bloomsbury   General & Literary Fiction  \n",
       "28    1,616,068  Hodder & Stoughton   General & Literary Fiction  \n",
       "29    1,583,992          Bloomsbury   General & Literary Fiction  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "87a41209",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver6.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3f8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7.Scrape the details most watched tv series of all time from imdb.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0db0b905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SNEHAL\\AppData\\Local\\Temp\\ipykernel_25528\\3339606480.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver7 = webdriver.Chrome(r\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver7 = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver7.get('https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5ee1a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "Span = []\n",
    "Genre = []\n",
    "Votes = []\n",
    "Runtime = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "42714320",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = driver7.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]//h3//a')\n",
    "for i in name:\n",
    "    if i.text is None:\n",
    "        Name.append('--')\n",
    "    else:\n",
    "        Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a54c42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "span = driver7.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]//h3//span[2]')\n",
    "for i in span:\n",
    "    if i.text is None:\n",
    "        Span.append('--')\n",
    "    else:\n",
    "        Span.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a08dba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap genre\n",
    "gen = driver7.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]//span[5]')\n",
    "for i in gen:\n",
    "    if i.text is None:\n",
    "        Genre.append('--')\n",
    "    else:\n",
    "        Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e9cfb33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap rating\n",
    "Rat = []\n",
    "rat = driver7.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]/span[2]')\n",
    "for i in rat:\n",
    "    if i.text is None:\n",
    "        Rat.append('--')\n",
    "    else:\n",
    "        Rat.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f0e4ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap vote\n",
    "vote = driver7.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]//p[4]//span[2]')\n",
    "for i in vote:\n",
    "    if i.text is None:\n",
    "        Votes.append('--')\n",
    "    else:\n",
    "        Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1a975a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = driver7.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]//span[3]')\n",
    "for i in run:\n",
    "    if i.text is None:\n",
    "        Runtime.append('--')\n",
    "    else:\n",
    "        Runtime.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f0c9c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.DataFrame([])\n",
    "df7['Series Name'] = Name[:100]\n",
    "df7['Span'] = Span[:100]\n",
    "df7['Genre'] = Genre[:100]\n",
    "df7['Rating'] =Rat[:100]\n",
    "df7['Votes'] = Votes[:100]\n",
    "df7['Runtime'] = Runtime[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "025f1a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series Name</th>\n",
       "      <th>Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,174,247</td>\n",
       "      <td>57 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,252,048</td>\n",
       "      <td>51 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,032,745</td>\n",
       "      <td>44 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>7.5</td>\n",
       "      <td>303,648</td>\n",
       "      <td>60 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,810</td>\n",
       "      <td>43 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7.4</td>\n",
       "      <td>51,977</td>\n",
       "      <td>42 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,008</td>\n",
       "      <td>50 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>8.1</td>\n",
       "      <td>208,593</td>\n",
       "      <td>42 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>7</td>\n",
       "      <td>43,409</td>\n",
       "      <td>45 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>8.6</td>\n",
       "      <td>260,329</td>\n",
       "      <td>572 min</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Series Name         Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Rating      Votes  Runtime  \n",
       "0     9.2  2,174,247   57 min  \n",
       "1     8.7  1,252,048   51 min  \n",
       "2     8.1  1,032,745   44 min  \n",
       "3     7.5    303,648   60 min  \n",
       "4     7.6    262,810   43 min  \n",
       "..    ...        ...      ...  \n",
       "95    7.4     51,977   42 min  \n",
       "96    7.8     64,008   50 min  \n",
       "97    8.1    208,593   42 min  \n",
       "98      7     43,409   45 min  \n",
       "99    8.6    260,329  572 min  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2350689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver7.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09111150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8.Details of Datasetsfrom UCI machine learning repositories. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "155c6ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SNEHAL\\AppData\\Local\\Temp\\ipykernel_25528\\3787116823.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver8 = webdriver.Chrome(r\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver8 = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver8.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d8a15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = driver8.find_element(By.XPATH,'//div[@class=\"flex flex-wrap justify-center gap-5\"]//a')\n",
    "data.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ceff5f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap datasets\n",
    "Dataset = []\n",
    "sets = driver8.find_elements(By.XPATH,'//h2[@class=\"truncate text-primary\"]')\n",
    "for i in sets:\n",
    "    if i.text is None:\n",
    "        Dataset.append('--')\n",
    "    else:\n",
    "        Dataset.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8ba166bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap data type\n",
    "d_type = []\n",
    "type1 = driver8.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]//div[2]//span')\n",
    "for i in type1:\n",
    "    if i.text is None:\n",
    "        d_type.append('--')\n",
    "    else:\n",
    "        d_type.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c66607c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification...... task scrap\n",
    "Task = []\n",
    "task = driver8.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]//div[1]//span')\n",
    "for i in task:\n",
    "    if i.text is None:\n",
    "        Task.append('--')\n",
    "    else:\n",
    "        Task.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "05e32899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click scrap attribute type\n",
    "Attribute_Type = []\n",
    "att=driver8.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 overflow-x-auto\"]//table//tbody//td[2]')\n",
    "for i in att:\n",
    "    if i.text is None :\n",
    "        Attribute_Type.append(\"--\") \n",
    "    else:\n",
    "        Attribute_Type.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "70b78ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap no of instances\n",
    "Ins = []\n",
    "ins=driver8.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]//div[3]//span')\n",
    "for i in ins:\n",
    "    if i.text is None :\n",
    "        Ins.append(\"--\") \n",
    "    else:\n",
    "        Ins.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "874cc6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Att_no = []\n",
    "atnum =driver8.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]//div[4]//span')\n",
    "for i in atnum:\n",
    "    if i.text is None :\n",
    "        Att_no.append(\"--\") \n",
    "    else:\n",
    "        Att_no.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "54177bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Year = []\n",
    "yr =driver8.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 overflow-x-auto\"]//table//tbody//td[3]')\n",
    "for i in yr:\n",
    "    if i.text is None :\n",
    "        Year.append(\"--\") \n",
    "    else:\n",
    "        Year.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b7527a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = pd.DataFrame([])\n",
    "df8['Dataset'] = Dataset[:15]\n",
    "df8['Data Type']=d_type[:15]\n",
    "df8['Task'] = Task[:15]\n",
    "df8['Year'] = Year[:15]\n",
    "df8['Attribute Type'] =Attribute_Type[:15] \n",
    "df8['No of Instance'] = Ins[:15]\n",
    "df8['No of Attribute'] = Att_no[:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "19f3881e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Year</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instance</th>\n",
       "      <th>No of Attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate, Domain-Theory</td>\n",
       "      <td>Classification</td>\n",
       "      <td>7/1/1988</td>\n",
       "      <td>Categorical, Real, Integer</td>\n",
       "      <td>125 Instances</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Regression, Clustering</td>\n",
       "      <td>7/1/1988</td>\n",
       "      <td>Real</td>\n",
       "      <td>2.08M Instances</td>\n",
       "      <td>9 Attributes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate, Data-Generator</td>\n",
       "      <td>Classification</td>\n",
       "      <td>5/1/1996</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td></td>\n",
       "      <td>22 Attributes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression, Clustering</td>\n",
       "      <td>9/14/2020</td>\n",
       "      <td>N/A</td>\n",
       "      <td>10K Instances</td>\n",
       "      <td>22 Attributes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>226 Instances</td>\n",
       "      <td>69 Attributes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>7/1/1991</td>\n",
       "      <td>Real</td>\n",
       "      <td>6.65K Instances</td>\n",
       "      <td>15 Attributes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wine</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6/1/1997</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>68.04K Instances</td>\n",
       "      <td>89 Attributes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate, Data-Generator</td>\n",
       "      <td>Classification</td>\n",
       "      <td>11/1/1995</td>\n",
       "      <td>Categorical</td>\n",
       "      <td></td>\n",
       "      <td>7 Attributes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate, Spatial</td>\n",
       "      <td>Classification</td>\n",
       "      <td>4/27/1987</td>\n",
       "      <td>Real</td>\n",
       "      <td>67.56K Instances</td>\n",
       "      <td>42 Attributes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate, Data-Generator</td>\n",
       "      <td>Classification</td>\n",
       "      <td>12/1/1995</td>\n",
       "      <td>N/A</td>\n",
       "      <td>5K Instances</td>\n",
       "      <td>40 Attributes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Abalone</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7/11/1988</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>9/1/1987</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>10.3K Instances</td>\n",
       "      <td>561 Attributes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Glass Identification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>11/17/1994</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>101.77K Instances</td>\n",
       "      <td>47 Attributes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Statlog (German Credit Data)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>5/1/1996</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>5.47K Instances</td>\n",
       "      <td>10 Attributes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Census Income</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression, Clustering</td>\n",
       "      <td>7/15/1992</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>299 Instances</td>\n",
       "      <td>13 Attributes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Dataset                     Data Type  \\\n",
       "0                                   Iris   Multivariate, Domain-Theory   \n",
       "1                          Heart Disease     Multivariate, Time-Series   \n",
       "2                                  Adult  Multivariate, Data-Generator   \n",
       "3                       Dry Bean Dataset                  Multivariate   \n",
       "4                               Diabetes                  Multivariate   \n",
       "5             Rice (Cammeo and Osmancik)     Multivariate, Time-Series   \n",
       "6                                   Wine                                 \n",
       "7                         Car Evaluation  Multivariate, Data-Generator   \n",
       "8   Breast Cancer Wisconsin (Diagnostic)         Multivariate, Spatial   \n",
       "9                               Mushroom  Multivariate, Data-Generator   \n",
       "10                               Abalone                                 \n",
       "11                         Breast Cancer     Multivariate, Time-Series   \n",
       "12                  Glass Identification                  Multivariate   \n",
       "13          Statlog (German Credit Data)                  Multivariate   \n",
       "14                         Census Income                  Multivariate   \n",
       "\n",
       "                                      Task        Year  \\\n",
       "0                           Classification    7/1/1988   \n",
       "1                   Regression, Clustering    7/1/1988   \n",
       "2                           Classification    5/1/1996   \n",
       "3   Classification, Regression, Clustering   9/14/2020   \n",
       "4                           Classification         N/A   \n",
       "5                           Classification    7/1/1991   \n",
       "6                                             6/1/1997   \n",
       "7                           Classification   11/1/1995   \n",
       "8                           Classification   4/27/1987   \n",
       "9                           Classification   12/1/1995   \n",
       "10                                           7/11/1988   \n",
       "11              Classification, Clustering    9/1/1987   \n",
       "12              Classification, Clustering  11/17/1994   \n",
       "13                          Classification    5/1/1996   \n",
       "14  Classification, Regression, Clustering   7/15/1992   \n",
       "\n",
       "                Attribute Type     No of Instance No of Attribute  \n",
       "0   Categorical, Real, Integer      125 Instances                  \n",
       "1                         Real    2.08M Instances    9 Attributes  \n",
       "2         Categorical, Integer                      22 Attributes  \n",
       "3                          N/A      10K Instances   22 Attributes  \n",
       "4                  Categorical      226 Instances   69 Attributes  \n",
       "5                         Real    6.65K Instances   15 Attributes  \n",
       "6                  Categorical   68.04K Instances   89 Attributes  \n",
       "7                  Categorical                       7 Attributes  \n",
       "8                         Real   67.56K Instances   42 Attributes  \n",
       "9                          N/A       5K Instances   40 Attributes  \n",
       "10                                                                 \n",
       "11        Categorical, Integer    10.3K Instances  561 Attributes  \n",
       "12               Integer, Real  101.77K Instances   47 Attributes  \n",
       "13               Integer, Real    5.47K Instances   10 Attributes  \n",
       "14        Categorical, Integer      299 Instances   13 Attributes  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d624bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9. Scrap Naukri.com Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dbb93fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SNEHAL\\AppData\\Local\\Temp\\ipykernel_25528\\3954587677.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver9 = webdriver.Chrome(r\"chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver9 = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver9.get('https://www.naukri.com/hr-recruiters-consultants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "20c13597",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver9.find_element(By.XPATH, '//button[@class=\"nI-gNb-sb__icon-wrapper\"]//span')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "47e8ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = driver9.find_element(By.XPATH,'//input[@class=\"suggestor-input \"]')\n",
    "text.send_keys('Data Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6d461ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver9.find_element(By.XPATH,'//span[@class=\"ni-gnb-icn ni-gnb-icn-search\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b17af5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = []\n",
    "name = driver9.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]') \n",
    "for i in name:\n",
    "    Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "abb0da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Company = []\n",
    "com = driver9.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]') \n",
    "for i in com:\n",
    "    Company.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0acf83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap skill \n",
    "Skill = []\n",
    "skill = driver9.find_elements(By.XPATH,'//ul[@class=\"tags has-description\"]') \n",
    "for i in skill:\n",
    "    Skill.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "89131975",
   "metadata": {},
   "outputs": [],
   "source": [
    "Location = []\n",
    "loc = driver9.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]') \n",
    "for i in loc:\n",
    "    Location.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f2d6b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Requirement = []\n",
    "req = driver9.find_elements(By.XPATH,'//div[@class=\"ellipsis job-description\"]') \n",
    "for i in req:\n",
    "    Requirement.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ec92c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = pd.DataFrame([])\n",
    "df9['Title'] = Name\n",
    "df9['Company'] = Company\n",
    "df9['Skills'] = Skill\n",
    "df9['Location'] = Location\n",
    "df9['Requirement']= Requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e840094e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "      <th>Requirement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Arbeit Associates</td>\n",
       "      <td>SQL\\nPython\\nAnalytics\\nGoogle Analytics\\nData...</td>\n",
       "      <td>Hybrid - Gurgaon/ Gurugram, Haryana, Bangalore...</td>\n",
       "      <td>Minimum 3-7 years of experience working closel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr Analyst - Data Science and Analytics</td>\n",
       "      <td>Transunion</td>\n",
       "      <td>Analytics\\nFinance\\nBusiness intelligence\\nQua...</td>\n",
       "      <td>Pune, Chennai</td>\n",
       "      <td>Here, we will not only understand your stats j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manager/Sr. Manager - GPS Safety Data Sciences</td>\n",
       "      <td>Eli Lilly And Company</td>\n",
       "      <td>GPS\\nOperations\\nHealthcare\\nSR\\nDevelopment\\n...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bachelordegree within a health science, Mathem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Bizongo</td>\n",
       "      <td>Vision\\nAnalytics\\nDeep Learning\\nNetworking\\n...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Proven experience as a Machine Learning Engine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Engineer II- Data Science &amp; Analytics</td>\n",
       "      <td>Raytheon Technologies</td>\n",
       "      <td>Data Science\\nstatistical modeling\\nmachine le...</td>\n",
       "      <td>Hybrid - Bangalore/ Bengaluru, Karnataka(Yelah...</td>\n",
       "      <td>Aftermarket &amp; Sustainment Engineering (ASE), b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Augusta Infotech</td>\n",
       "      <td>python\\nnumpy\\nmachine learning\\ntensorflow\\nP...</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka(Electronic City)</td>\n",
       "      <td>Data ScienceWe are looking for a highly motiva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L&amp;D Trainer - Python &amp; Data Science/Data Analy...</td>\n",
       "      <td>AVE-Promagne Business Solutions</td>\n",
       "      <td>Data Analytics\\nIT training\\nTraining\\nMachine...</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Any Graduate in IT / Computer Science, BTech /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Tredence</td>\n",
       "      <td>Data Science\\nText Analytics\\nNew business dev...</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>. Bachelors or Masters degree in a quantitativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Conneqt Digital</td>\n",
       "      <td>Data Science\\nAzure\\nArtificial Intelligence\\n...</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru</td>\n",
       "      <td>Notice Period: Immediate Joiner (we are lookin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Science Manager - Machine Learning/Predic...</td>\n",
       "      <td>HyrEzy Talent Solution</td>\n",
       "      <td>Data Science\\nNeural networks\\nDevelopment\\nPr...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>They are seeking a Data Science Manager intere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Senior Manager Data Science Global</td>\n",
       "      <td>Red Hat</td>\n",
       "      <td>Machine Learning\\nMachine\\nPython\\nScience\\nOp...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>The Data Development, Insights &amp; Strategy team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Unit Manager - Payments - Data Science/Senior ...</td>\n",
       "      <td>Bajaj Finserv Ltd.</td>\n",
       "      <td>DBMS\\nPython\\nArchitecture\\nData management\\nD...</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Bachelors Degree in computer science, Math, Ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Senior Manager-Data Science</td>\n",
       "      <td>Ola</td>\n",
       "      <td>Data Science\\nR\\nNatural Language Processing\\n...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Founded in Jan 2011 by IIT Bombay alumni Bhavi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sr Programmer - Python / Data Science Developer</td>\n",
       "      <td>Ajanta Pharma</td>\n",
       "      <td>Data Modeling\\nPython\\nNumpy\\nWeb technologies...</td>\n",
       "      <td>Mumbai, Maharashtra, Mumbai Suburban, Maharashtra</td>\n",
       "      <td>Certification in data science would be and add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Koch Industries</td>\n",
       "      <td>Data Science\\nSAS\\nScience\\nData analysis\\nDat...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3+ years of experience delivering results from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AI and Data Science Engineer</td>\n",
       "      <td>Rtwo Healthcare Solutions Llp</td>\n",
       "      <td>Analytical\\nData Science\\nMonitoring\\nHealthca...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bachelors or master s degree in computer scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Science Senior Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Data Science\\nPredictive Modeling\\nmachine lea...</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Please note that this role may require you to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Science, AI/ML Professional</td>\n",
       "      <td>QA InfoTech Pvt. Ltd</td>\n",
       "      <td>Cloud\\nCloud computing\\nData Science\\nSimulati...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>R language experience is a must . Ability to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Science - AI/ML Professional</td>\n",
       "      <td>QA InfoTech Pvt. Ltd</td>\n",
       "      <td>Ml\\nMySQL\\nSDLC\\nJIRA\\nData Science\\nCloud com...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>R language experience is a must . Ability to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Science, AI/ML Professional</td>\n",
       "      <td>Zenq</td>\n",
       "      <td>Analysis\\nArtificial Intelligence\\nData analys...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>7+ Year s Experience in Data Science, AI/ML Re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                               Data Science Engineer   \n",
       "1             Sr Analyst - Data Science and Analytics   \n",
       "2      Manager/Sr. Manager - GPS Safety Data Sciences   \n",
       "3                               Data Science Engineer   \n",
       "4               Engineer II- Data Science & Analytics   \n",
       "5                               Data Science Engineer   \n",
       "6   L&D Trainer - Python & Data Science/Data Analy...   \n",
       "7                                Data Science Manager   \n",
       "8                               Data Science Engineer   \n",
       "9   Data Science Manager - Machine Learning/Predic...   \n",
       "10                 Senior Manager Data Science Global   \n",
       "11  Unit Manager - Payments - Data Science/Senior ...   \n",
       "12                        Senior Manager-Data Science   \n",
       "13    Sr Programmer - Python / Data Science Developer   \n",
       "14                               Data Science Analyst   \n",
       "15                       AI and Data Science Engineer   \n",
       "16                        Data Science Senior Analyst   \n",
       "17                   Data Science, AI/ML Professional   \n",
       "18                  Data Science - AI/ML Professional   \n",
       "19                   Data Science, AI/ML Professional   \n",
       "\n",
       "                            Company  \\\n",
       "0                 Arbeit Associates   \n",
       "1                        Transunion   \n",
       "2             Eli Lilly And Company   \n",
       "3                           Bizongo   \n",
       "4             Raytheon Technologies   \n",
       "5                  Augusta Infotech   \n",
       "6   AVE-Promagne Business Solutions   \n",
       "7                          Tredence   \n",
       "8                   Conneqt Digital   \n",
       "9            HyrEzy Talent Solution   \n",
       "10                          Red Hat   \n",
       "11               Bajaj Finserv Ltd.   \n",
       "12                              Ola   \n",
       "13                    Ajanta Pharma   \n",
       "14                  Koch Industries   \n",
       "15    Rtwo Healthcare Solutions Llp   \n",
       "16                        Accenture   \n",
       "17             QA InfoTech Pvt. Ltd   \n",
       "18             QA InfoTech Pvt. Ltd   \n",
       "19                             Zenq   \n",
       "\n",
       "                                               Skills  \\\n",
       "0   SQL\\nPython\\nAnalytics\\nGoogle Analytics\\nData...   \n",
       "1   Analytics\\nFinance\\nBusiness intelligence\\nQua...   \n",
       "2   GPS\\nOperations\\nHealthcare\\nSR\\nDevelopment\\n...   \n",
       "3   Vision\\nAnalytics\\nDeep Learning\\nNetworking\\n...   \n",
       "4   Data Science\\nstatistical modeling\\nmachine le...   \n",
       "5   python\\nnumpy\\nmachine learning\\ntensorflow\\nP...   \n",
       "6   Data Analytics\\nIT training\\nTraining\\nMachine...   \n",
       "7   Data Science\\nText Analytics\\nNew business dev...   \n",
       "8   Data Science\\nAzure\\nArtificial Intelligence\\n...   \n",
       "9   Data Science\\nNeural networks\\nDevelopment\\nPr...   \n",
       "10  Machine Learning\\nMachine\\nPython\\nScience\\nOp...   \n",
       "11  DBMS\\nPython\\nArchitecture\\nData management\\nD...   \n",
       "12  Data Science\\nR\\nNatural Language Processing\\n...   \n",
       "13  Data Modeling\\nPython\\nNumpy\\nWeb technologies...   \n",
       "14  Data Science\\nSAS\\nScience\\nData analysis\\nDat...   \n",
       "15  Analytical\\nData Science\\nMonitoring\\nHealthca...   \n",
       "16  Data Science\\nPredictive Modeling\\nmachine lea...   \n",
       "17  Cloud\\nCloud computing\\nData Science\\nSimulati...   \n",
       "18  Ml\\nMySQL\\nSDLC\\nJIRA\\nData Science\\nCloud com...   \n",
       "19  Analysis\\nArtificial Intelligence\\nData analys...   \n",
       "\n",
       "                                             Location  \\\n",
       "0   Hybrid - Gurgaon/ Gurugram, Haryana, Bangalore...   \n",
       "1                                       Pune, Chennai   \n",
       "2                                 Bangalore/Bengaluru   \n",
       "3                                 Bangalore/Bengaluru   \n",
       "4   Hybrid - Bangalore/ Bengaluru, Karnataka(Yelah...   \n",
       "5    Bangalore/ Bengaluru, Karnataka(Electronic City)   \n",
       "6   Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "7   Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "8                        Hybrid - Bangalore/Bengaluru   \n",
       "9                                 Bangalore/Bengaluru   \n",
       "10                                Bangalore/Bengaluru   \n",
       "11                                               Pune   \n",
       "12                                Bangalore/Bengaluru   \n",
       "13  Mumbai, Maharashtra, Mumbai Suburban, Maharashtra   \n",
       "14                                Bangalore/Bengaluru   \n",
       "15                                Bangalore/Bengaluru   \n",
       "16                                             Mumbai   \n",
       "17                                Bangalore/Bengaluru   \n",
       "18                                Bangalore/Bengaluru   \n",
       "19                                Bangalore/Bengaluru   \n",
       "\n",
       "                                          Requirement  \n",
       "0   Minimum 3-7 years of experience working closel...  \n",
       "1   Here, we will not only understand your stats j...  \n",
       "2   Bachelordegree within a health science, Mathem...  \n",
       "3   Proven experience as a Machine Learning Engine...  \n",
       "4   Aftermarket & Sustainment Engineering (ASE), b...  \n",
       "5   Data ScienceWe are looking for a highly motiva...  \n",
       "6   Any Graduate in IT / Computer Science, BTech /...  \n",
       "7   . Bachelors or Masters degree in a quantitativ...  \n",
       "8   Notice Period: Immediate Joiner (we are lookin...  \n",
       "9   They are seeking a Data Science Manager intere...  \n",
       "10  The Data Development, Insights & Strategy team...  \n",
       "11  Bachelors Degree in computer science, Math, Ph...  \n",
       "12  Founded in Jan 2011 by IIT Bombay alumni Bhavi...  \n",
       "13  Certification in data science would be and add...  \n",
       "14  3+ years of experience delivering results from...  \n",
       "15  Bachelors or master s degree in computer scien...  \n",
       "16  Please note that this role may require you to ...  \n",
       "17  R language experience is a must . Ability to l...  \n",
       "18  R language experience is a must . Ability to l...  \n",
       "19  7+ Year s Experience in Data Science, AI/ML Re...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "dad167b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver9.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b87d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95977915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc674a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec955d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f71e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75307c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b6b4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a01404a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
